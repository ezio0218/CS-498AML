{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_file():\n",
    "    file_list1 = []\n",
    "    file_list2 = []\n",
    "    file_list3 = []\n",
    "    file_list4 = []\n",
    "    file_list5 = []\n",
    "    file_list6 = []\n",
    "    file_list7 = []\n",
    "    file_list8 = []\n",
    "    file_list9 = []\n",
    "    file_list10 = []\n",
    "    file_list11 = []\n",
    "    file_list12 = []\n",
    "    file_list13 = []\n",
    "    file_list14 = []\n",
    "    for root, dirs, files in os.walk(\"HMP_DataSet/Brush_teeth\"):  \n",
    "        for filename in files:\n",
    "            file_list1.append(\"HMP_DataSet/Brush_teeth/\" + filename)\n",
    "    for root, dirs, files in os.walk(\"HMP_DataSet/Climb_stairs\"):  \n",
    "        for filename in files:\n",
    "            file_list2.append(\"HMP_DataSet/Climb_stairs/\" + filename)\n",
    "    for root, dirs, files in os.walk(\"HMP_DataSet/Comb_hair\"):  \n",
    "        for filename in files:\n",
    "            file_list3.append(\"HMP_DataSet/Comb_hair/\" + filename)\n",
    "    for root, dirs, files in os.walk(\"HMP_DataSet/Descend_stairs\"):  \n",
    "        for filename in files:\n",
    "            file_list4.append(\"HMP_DataSet/Descend_stairs/\" + filename)\n",
    "    for root, dirs, files in os.walk(\"HMP_DataSet/Drink_glass\"):  \n",
    "        for filename in files:\n",
    "            file_list5.append(\"HMP_DataSet/Drink_glass/\" + filename)\n",
    "    for root, dirs, files in os.walk(\"HMP_DataSet/Eat_meat\"):  \n",
    "        for filename in files:\n",
    "            file_list6.append(\"HMP_DataSet/Eat_meat/\" + filename)\n",
    "    for root, dirs, files in os.walk(\"HMP_DataSet/Eat_soup\"):  \n",
    "        for filename in files:\n",
    "            file_list7.append(\"HMP_DataSet/Eat_soup/\" + filename)\n",
    "    for root, dirs, files in os.walk(\"HMP_DataSet/Getup_bed\"):  \n",
    "        for filename in files:\n",
    "            file_list8.append(\"HMP_DataSet/Getup_bed/\" + filename)\n",
    "    for root, dirs, files in os.walk(\"HMP_DataSet/Liedown_bed\"):  \n",
    "        for filename in files:\n",
    "            file_list9.append(\"HMP_DataSet/Liedown_bed/\" + filename)\n",
    "    for root, dirs, files in os.walk(\"HMP_DataSet/Pour_water\"):  \n",
    "        for filename in files:\n",
    "            file_list10.append(\"HMP_DataSet/Pour_water/\" + filename)\n",
    "    for root, dirs, files in os.walk(\"HMP_DataSet/Sitdown_chair\"):  \n",
    "        for filename in files:\n",
    "            file_list11.append(\"HMP_DataSet/Sitdown_chair/\" + filename)\n",
    "    for root, dirs, files in os.walk(\"HMP_DataSet/Standup_chair\"):  \n",
    "        for filename in files:\n",
    "            file_list12.append(\"HMP_DataSet/Standup_chair/\" + filename)\n",
    "    for root, dirs, files in os.walk(\"HMP_DataSet/Use_telephone\"):  \n",
    "        for filename in files:\n",
    "            file_list13.append(\"HMP_DataSet/Use_telephone/\" + filename)\n",
    "    for root, dirs, files in os.walk(\"HMP_DataSet/Walk\"):  \n",
    "        for filename in files:\n",
    "            file_list14.append(\"HMP_DataSet/Walk/\" + filename)\n",
    "    File_list = [file_list1, file_list2, file_list3, file_list4, file_list5, file_list6, file_list7, file_list8, file_list9,file_list10,file_list11,file_list12,file_list13,file_list14]\n",
    "    return File_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_list = get_total_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getData():\n",
    "    value_list = list()\n",
    "    data_raw_list = list()\n",
    "    for file in File_list:\n",
    "        data_list = list()\n",
    "        for s in range(len(file)):\n",
    "            data_raw = pd.read_csv(file[s], header = None, sep = ' ', dtype = float)\n",
    "            data = np.asarray(data_raw)\n",
    "            data_raw_list.append(data_raw)\n",
    "            data_list.append(data)\n",
    "        value_list.append(data_list)\n",
    "    return value_list, data_raw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenData(data_raw_list, Size:int):    \n",
    "    new_data = list()\n",
    "    for i in range(len(data_raw_list)):\n",
    "        d = np.asarray(data_raw_list[i])\n",
    "        n, m = d.shape\n",
    "        if n % Size == 0:\n",
    "            c = d.reshape(int(n/Size), int(3*Size))\n",
    "            C = pd.DataFrame(c)\n",
    "            new_data.append(C)\n",
    "        if n % Size != 0:\n",
    "            overlap = d[-Size:,]\n",
    "            remained = d[:int(Size*(n//Size)),]\n",
    "            con = np.concatenate((remained, overlap), axis=0)\n",
    "            f, x = con.shape\n",
    "            c = con.reshape(int(f/Size), int(3*Size))\n",
    "            C = pd.DataFrame(c)\n",
    "            new_data.append(C)\n",
    "    flat = pd.concat(new_data, ignore_index=True)\n",
    "    flattened_data = np.asarray(flat)\n",
    "    return flattened_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_list, data_raw_list = getData()\n",
    "flattened_data = flattenData(data_raw_list, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_means_level1(k, flattened_data):\n",
    "    model = KMeans(n_clusters = k).fit(flattened_data)\n",
    "    l = model.predict(flattened_data)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = K_means_level1(5, flattened_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_means_level2(k, k1, l):\n",
    "    n = l.shape[0]\n",
    "    data_new = np.concatenate((flattened_data,l.reshape(n,1)),axis=1) \n",
    "    df_new = pd.DataFrame(data_new)\n",
    "    df_list = list()\n",
    "    center_list = list()\n",
    "    index_list = list()\n",
    "    for i in range(k):\n",
    "        df = df_new[df_new[96]==i].drop([96],axis=1,inplace=False)\n",
    "        df_list.append(df)\n",
    "    for k in range(len(df_list)):\n",
    "        data_k = np.asarray(df_list[k])\n",
    "        model = KMeans(n_clusters = k1).fit(data_k)\n",
    "        center_list.append(model.cluster_centers_)\n",
    "        index = model.predict(data_k)\n",
    "        for j in range(index.shape[0]):\n",
    "            index[j] = k*12 + index[j]\n",
    "        index_list.append(index)\n",
    "    return center_list, index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_list, index_list = K_means_level2(5, 12, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfo_cluster(center_list, index_list, flattened_data):\n",
    "    len_center = len(center_list)\n",
    "    dim_center, num_figure = center_list[0].shape\n",
    "    center_total = np.asarray(center_list).reshape(int(len_center*dim_center), num_figure)\n",
    "    number = flattened_data.shape[0]\n",
    "    index_stat = np.zeros(int(len_center*dim_center))\n",
    "    for i in range(int(len_center*dim_center)):\n",
    "        for j in range(len(index_list)):\n",
    "            for k in range(index_list[j].shape[0]):\n",
    "                if index_list[j][k] == i:\n",
    "                    index_stat[i] += 1\n",
    "    return center_total, index_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_total, index_stat = getInfo_cluster(center_list, index_list, flattened_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center_total.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 60 artists>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(index_stat.shape[0]), index_stat/flattened_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(value_list):\n",
    "    label_list = []\n",
    "    train = []\n",
    "    test = []\n",
    "    train_label = []\n",
    "    test_label = []\n",
    "    for i in range(len(value_list)):\n",
    "        label = []\n",
    "        for j in range(len(value_list[i])):\n",
    "            label.append(i + 1)\n",
    "        label_list.append(label)\n",
    "    for s in range(len(value_list)):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(value_list[s], label_list[s], test_size = 1/3)\n",
    "        train.append(x_train)\n",
    "        train_label.append(y_train)\n",
    "        test.append(x_test)\n",
    "        test_label.append(y_test)\n",
    "    return train, test, train_label, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CV(value_list):\n",
    "    label_list = []\n",
    "    train_1 = []\n",
    "    train_2 = []\n",
    "    train_3 = []\n",
    "    test_1 = []\n",
    "    test_2 = []\n",
    "    test_3 = []\n",
    "    train_label_1 = []\n",
    "    train_label_2 = []\n",
    "    train_label_3 = []\n",
    "    test_label_1 = []\n",
    "    test_label_2 = []\n",
    "    test_label_3 = []\n",
    "    Train = []\n",
    "    Test = []\n",
    "    Train_label = []\n",
    "    Test_label = []\n",
    "    for i in range(len(value_list)):\n",
    "        label = []\n",
    "        for j in range(len(value_list[i])):\n",
    "            label.append(i + 1)\n",
    "        label_list.append(label)\n",
    "    for s in range(len(value_list)):\n",
    "        f1 = value_list[s][0:int((1/3)*len(value_list[s]))]\n",
    "        f2 = value_list[s][int((1/3)*len(value_list[s])):2*int((1/3)*len(value_list[s]))]\n",
    "        f3 = value_list[s][2*int((1/3)*len(value_list[s])):len(value_list[s])]\n",
    "        y1 = label_list[s][0:int((1/3)*len(label_list[s]))]\n",
    "        y2 = label_list[s][int((1/3)*len(label_list[s])):2*int((1/3)*len(label_list[s]))]\n",
    "        y3 = label_list[s][2*int((1/3)*len(label_list[s])):len(label_list[s])]\n",
    "        train_1.append(f1+f2)\n",
    "        train_2.append(f1+f3)\n",
    "        train_3.append(f2+f3)\n",
    "        test_1.append(f3)\n",
    "        test_2.append(f2)\n",
    "        test_3.append(f1)\n",
    "        train_label_1.append(y1+y2)\n",
    "        train_label_2.append(y1+y3)\n",
    "        train_label_3.append(y2+y3)\n",
    "        test_label_1.append(y3)\n",
    "        test_label_2.append(y2)\n",
    "        test_label_3.append(y1)\n",
    "    Train.append(train_1)\n",
    "    Train.append(train_2)\n",
    "    Train.append(train_3)\n",
    "    Test.append(test_1)\n",
    "    Test.append(test_2)\n",
    "    Test.append(test_3)\n",
    "    Train_label.append(train_label_1)\n",
    "    Train_label.append(train_label_2)\n",
    "    Train_label.append(train_label_3)\n",
    "    Test_label.append(test_label_1)\n",
    "    Test_label.append(test_label_2)\n",
    "    Test_label.append(test_label_3)\n",
    "    return Train, Test, Train_label, Test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenData2(data, Size:int):  \n",
    "    flat = []\n",
    "    for i in range(len(data)):\n",
    "        flat_in =[]\n",
    "        for l in range(len(data[i])):\n",
    "            d = data[i][l]\n",
    "            n, m = d.shape\n",
    "            if n % Size == 0:\n",
    "                c = d.reshape(int(n/Size), int(3*Size))\n",
    "                flat_in.append(c)\n",
    "            if n % Size != 0:\n",
    "                overlap = d[-Size:,]\n",
    "                remained = d[:int(Size*(n//Size)),]\n",
    "                con = np.concatenate((remained, overlap), axis=0)\n",
    "                f, x = con.shape\n",
    "                c = con.reshape(int(f/Size), int(3*Size))\n",
    "                flat_in.append(c)\n",
    "        flat.append(flat_in)\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_array(data):\n",
    "    new_data = []\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            new_data.append(data[i][j])\n",
    "    data = np.asarray(new_data) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def KNN_classifier(data_train, center_total):\n",
    "    KNN = KNeighborsClassifier(n_neighbors = 1) \n",
    "    n, m = center_total.shape\n",
    "    KNN.fit(center_total, range(n))\n",
    "    predict_list = []\n",
    "    for i in range(data_train.shape[0]):\n",
    "        y_pred = KNN.predict(data_train[i]) \n",
    "        predict_list.append(y_pred)\n",
    "    prediction = np.asarray(predict_list)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_classifier(data_train, center_total, estimators, depth):\n",
    "    RF = RandomForestClassifier(n_estimators = estimators, max_depth = depth)\n",
    "    n, m = center_total.shape\n",
    "    RF.fit(center_total, range(n))\n",
    "    predict_list = []\n",
    "    for i in range(data_train.shape[0]):\n",
    "        y_pred = RF.predict(data_train[i]) \n",
    "        predict_list.append(y_pred)\n",
    "    prediction = np.asarray(predict_list)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Mat(prediction, center_total):\n",
    "    n, m = center_total.shape\n",
    "    M = np.zeros((prediction.shape[0], n))\n",
    "    for i in range(n):\n",
    "        for j in range(prediction.shape[0]):\n",
    "            for k in range(prediction[j].shape[0]):\n",
    "                if prediction[j][k] == i:\n",
    "                    M[j][i] += 1 \n",
    "    for l in range(prediction.shape[0]):\n",
    "        q = np.sum(M[l])\n",
    "        for f in range(n):\n",
    "            M[l][f] = M[l][f]/q\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_classifier_2(M_train, M_test, label_train):\n",
    "    KNN = KNeighborsClassifier(n_neighbors = 1) \n",
    "    KNN.fit(M_train, label_train)\n",
    "    y_pred = KNN.predict(M_test) \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestClassifier_2(M_train, M_test, label_train, estimators, depth):\n",
    "    RF = RandomForestClassifier(n_estimators = estimators, max_depth = depth)\n",
    "    RF.fit(M_train, label_train)\n",
    "    y_pred = RF.predict(M_test) \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(pred_RF, label_test):\n",
    "    count = 0\n",
    "    for i in range(pred_RF.shape[0]):\n",
    "        if pred_RF[i] == label_test[i]:\n",
    "            count = count + 1\n",
    "    Acc = count/pred_RF.shape[0]\n",
    "    return Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    chunk_size = 32\n",
    "    K_mean_level1 = 10\n",
    "    K_mean_level2 = 10\n",
    "    estimators = 100\n",
    "    depth = 80\n",
    "    File_list = get_total_file()\n",
    "    value_list, data_raw_list = getData()\n",
    "    flattened_data = flattenData(data_raw_list, 32)\n",
    "    l = K_means_level1(10, flattened_data)\n",
    "    center_list, index_list = K_means_level2(10, 10, l)\n",
    "    center_total, index_stat = getInfo_cluster(center_list, index_list, flattened_data)\n",
    "    Train, Test, Train_label, Test_label = get_CV(value_list)\n",
    "    Acc = []\n",
    "    for j in range(len(Train)):\n",
    "        train = Train[j]\n",
    "        test = Test[j]\n",
    "        train_label = Train_label[j]\n",
    "        test_label = Test_label[j]\n",
    "        data_train = make_array(flattenData2(train, 32))\n",
    "        data_test = make_array(flattenData2(test, 32))\n",
    "        label_train = make_array(train_label)\n",
    "        label_test = make_array(test_label)\n",
    "        prediction_RF = RandomForest_classifier(data_train, center_total, estimators, depth)\n",
    "        prediction_RFtest = RandomForest_classifier(data_test, center_total, estimators, depth)\n",
    "        M_train_RF = generate_Mat(prediction_RF, center_total)\n",
    "        M_test_RF = generate_Mat(prediction_RFtest, center_total)\n",
    "        pred_RF = RandomForestClassifier_2(M_train_RF, M_test_RF, label_train, estimators, depth)\n",
    "        Acc.append(getAccuracy(pred_RF, label_test))\n",
    "    print(Acc)\n",
    "    return Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7003484320557491, 0.7101449275362319, 0.6594202898550725]\n"
     ]
    }
   ],
   "source": [
    "Acc = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
